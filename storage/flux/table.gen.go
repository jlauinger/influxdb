// Generated by tmpl
// https://github.com/benbjohnson/tmpl
//
// DO NOT EDIT!
// Source: table.gen.go.tmpl

package storageflux

import (
	"sync"

	"github.com/apache/arrow/go/arrow/array"
	"github.com/influxdata/flux"
	"github.com/influxdata/flux/arrow"
	"github.com/influxdata/flux/execute"
	"github.com/influxdata/flux/memory"
	"github.com/influxdata/influxdb/v2"
	"github.com/influxdata/influxdb/v2/models"
	storage "github.com/influxdata/influxdb/v2/storage/reads"
	"github.com/influxdata/influxdb/v2/tsdb/cursors"
)

//
// *********** Float ***********
//

type floatTable struct {
	table
	mu    sync.Mutex
	cur   cursors.FloatArrayCursor
	alloc *memory.Allocator
}

func newFloatTable(
	done chan struct{},
	cur cursors.FloatArrayCursor,
	bounds execute.Bounds,
	key flux.GroupKey,
	cols []flux.ColMeta,
	tags models.Tags,
	defs [][]byte,
	cache *tagsCache,
	alloc *memory.Allocator,
) *floatTable {
	t := &floatTable{
		table: newTable(done, bounds, key, cols, defs, cache, alloc),
		cur:   cur,
	}
	t.readTags(tags)
	t.advance()

	return t
}

func (t *floatTable) Close() {
	t.mu.Lock()
	if t.cur != nil {
		t.cur.Close()
		t.cur = nil
	}
	t.mu.Unlock()
}

func (t *floatTable) Statistics() cursors.CursorStats {
	t.mu.Lock()
	defer t.mu.Unlock()
	cur := t.cur
	if cur == nil {
		return cursors.CursorStats{}
	}
	cs := cur.Stats()
	return cursors.CursorStats{
		ScannedValues: cs.ScannedValues,
		ScannedBytes:  cs.ScannedBytes,
	}
}

func (t *floatTable) Do(f func(flux.ColReader) error) error {
	return t.do(f, t.advance)
}

func (t *floatTable) advance() bool {
	a := t.cur.Next()
	l := a.Len()
	if l == 0 {
		return false
	}

	// Retrieve the buffer for the data to avoid allocating
	// additional slices. If the buffer is still being used
	// because the references were retained, then we will
	// allocate a new buffer.
	cr := t.allocateBuffer(l)
	cr.cols[timeColIdx] = arrow.NewInt(a.Timestamps, t.alloc)
	cr.cols[valueColIdx] = t.toArrowBuffer(a.Values)
	t.appendTags(cr)
	t.appendBounds(cr)
	return true
}

// window table
type floatWindowTable struct {
	floatTable
	windowEvery int64
	arr         *cursors.FloatArray
	idxInArr    int
}

func newFloatWindowTable(
	done chan struct{},
	cur cursors.FloatArrayCursor,
	bounds execute.Bounds,
	every int64,
	key flux.GroupKey,
	cols []flux.ColMeta,
	tags models.Tags,
	defs [][]byte,
	cache *tagsCache,
	alloc *memory.Allocator,
) *floatWindowTable {
	t := &floatWindowTable{
		floatTable: floatTable{
			table: newTable(done, bounds, key, cols, defs, cache, alloc),
			cur:   cur,
		},
		windowEvery: every,
	}
	t.readTags(tags)
	t.advance()

	return t
}

func (t *floatWindowTable) advance() bool {
	if t.arr == nil {
		t.arr = t.cur.Next()
		if t.arr.Len() == 0 {
			t.arr = nil
			return false
		}
		t.idxInArr = 0
	}

	// Retrieve the buffer for the data to avoid allocating
	// additional slices. If the buffer is still being used
	// because the references were retained, then we will
	// allocate a new buffer.
	columnReader := t.allocateBuffer(1)
	// regain the window start time from the window end time
	rangeStart := int64(t.bounds.Start)
	rangeEnd := int64(t.bounds.Stop)
	stop := t.arr.Timestamps[t.idxInArr]
	start := stop - t.windowEvery
	if start < rangeStart {
		start = rangeStart
	}
	if stop > rangeEnd {
		stop = rangeEnd
	}
	columnReader.cols[startColIdx] = arrow.NewInt([]int64{start}, t.alloc)
	columnReader.cols[stopColIdx] = arrow.NewInt([]int64{stop}, t.alloc)
	columnReader.cols[windowedValueColIdx] = t.toArrowBuffer(t.arr.Values[t.idxInArr : t.idxInArr+1])
	t.appendTags(columnReader)
	t.idxInArr++
	if t.idxInArr == t.arr.Len() {
		t.arr = nil
	}
	return true
}

type floatCompleteWindowTable struct {
	floatTable
	windowEvery int64
	ts          int64

	// Buffered state from the underlying cursor.
	timestamps []int64
	values     []float64
	i          int
	done       bool
}

func newFloatCompleteWindowTable(
	done chan struct{},
	cur cursors.FloatArrayCursor,
	bounds execute.Bounds,
	every int64,
	key flux.GroupKey,
	cols []flux.ColMeta,
	tags models.Tags,
	defs [][]byte,
	cache *tagsCache,
	alloc *memory.Allocator,
) *floatCompleteWindowTable {
	start := int64(bounds.Start)
	t := &floatCompleteWindowTable{
		floatTable: floatTable{
			table: newTable(done, bounds, key, cols, defs, cache, alloc),
			cur:   cur,
		},
		windowEvery: every,
		ts:          start + (every - start%every),
	}
	t.readTags(tags)
	t.advance()

	return t
}

// createWindows will create the next set of windows for each interval.
// The ts parameter is the first interval's stop time.
func (t *floatCompleteWindowTable) createWindows(ts int64) (next int64, start, stop *array.Int64) {
	n := int((int64(t.bounds.Stop) - ts) / t.windowEvery)
	if n > maxWindowBufferSize {
		n = maxWindowBufferSize
	}

	stopB := arrow.NewIntBuilder(t.alloc)
	stopB.Resize(n)
	for i, ts := 0, ts; i < n; i, ts = i+1, ts+t.windowEvery {
		if i == n-1 && ts > int64(t.bounds.Stop) {
			stopB.Append(int64(t.bounds.Stop))
			continue
		}
		stopB.Append(ts)
		next = ts
	}
	stop = stopB.NewInt64Array()

	startB := arrow.NewIntBuilder(t.alloc)
	startB.Resize(n)
	for i, ts := 0, ts-t.windowEvery; i < n; i, ts = i+1, ts+t.windowEvery {
		if i == 0 && ts < int64(t.bounds.Start) {
			startB.Append(int64(t.bounds.Start))
			continue
		}
		startB.Append(ts)
	}
	start = startB.NewInt64Array()
	return next, start, stop
}

func (t *floatCompleteWindowTable) nextAt(ts int64) (v float64, ok bool) {
	if t.i >= len(t.timestamps) && !t.nextBuffer() {
		return
	} else if t.timestamps[t.i] != ts {
		return
	}
	v, ok = t.values[t.i], true
	t.i++
	return v, ok
}

func (t *floatCompleteWindowTable) nextBuffer() bool {
	if t.done {
		return false
	}

	a := t.cur.Next()
	if a.Len() == 0 {
		t.done = true
		return false
	}
	t.timestamps = a.Timestamps
	t.values = a.Values
	t.i = 0
	return true
}

func (t *floatCompleteWindowTable) appendValues(intervals []int64, appendValue func(v float64), appendNull func()) {
	for i := 0; i < len(intervals); i++ {
		if v, ok := t.nextAt(intervals[i]); ok {
			appendValue(v)
			continue
		}
		appendNull()
	}
}

func (t *floatCompleteWindowTable) advance() bool {
	if t.ts-t.windowEvery >= int64(t.bounds.Stop) {
		return false
	}

	var start, stop *array.Int64
	t.ts, start, stop = t.createWindows(t.ts)

	for {
		if len(t.timestamps) == 0 && !t.done {
			a := t.cur.Next()
			if a.Len() == 0 {
				t.done = true
				break
			}
		}
	}
	values := t.mergeValues(stop.Int64Values())

	// Retrieve the buffer for the data to avoid allocating
	// additional slices. If the buffer is still being used
	// because the references were retained, then we will
	// allocate a new buffer.
	cr := t.allocateBuffer(stop.Len())
	cr.cols[startColIdx] = start
	cr.cols[stopColIdx] = stop
	cr.cols[windowedValueColIdx] = values
	t.appendTags(cr)
	return true
}

// group table

type floatGroupTable struct {
	table
	mu  sync.Mutex
	gc  storage.GroupCursor
	cur cursors.FloatArrayCursor
}

func newFloatGroupTable(
	done chan struct{},
	gc storage.GroupCursor,
	cur cursors.FloatArrayCursor,
	bounds execute.Bounds,
	key flux.GroupKey,
	cols []flux.ColMeta,
	tags models.Tags,
	defs [][]byte,
	cache *tagsCache,
	alloc *memory.Allocator,
) *floatGroupTable {
	t := &floatGroupTable{
		table: newTable(done, bounds, key, cols, defs, cache, alloc),
		gc:    gc,
		cur:   cur,
	}
	t.readTags(tags)
	t.advance()

	return t
}

func (t *floatGroupTable) Close() {
	t.mu.Lock()
	if t.cur != nil {
		t.cur.Close()
		t.cur = nil
	}
	if t.gc != nil {
		t.gc.Close()
		t.gc = nil
	}
	t.mu.Unlock()
}

func (t *floatGroupTable) Do(f func(flux.ColReader) error) error {
	return t.do(f, t.advance)
}

func (t *floatGroupTable) advance() bool {
RETRY:
	a := t.cur.Next()
	l := a.Len()
	if l == 0 {
		if t.advanceCursor() {
			goto RETRY
		}

		return false
	}

	// Retrieve the buffer for the data to avoid allocating
	// additional slices. If the buffer is still being used
	// because the references were retained, then we will
	// allocate a new buffer.
	cr := t.allocateBuffer(l)
	cr.cols[timeColIdx] = arrow.NewInt(a.Timestamps, t.alloc)
	cr.cols[valueColIdx] = t.toArrowBuffer(a.Values)
	t.appendTags(cr)
	t.appendBounds(cr)
	return true
}

func (t *floatGroupTable) advanceCursor() bool {
	t.cur.Close()
	t.cur = nil
	for t.gc.Next() {
		cur := t.gc.Cursor()
		if cur == nil {
			continue
		}

		if typedCur, ok := cur.(cursors.FloatArrayCursor); !ok {
			// TODO(sgc): error or skip?
			cur.Close()
			t.err = &influxdb.Error{
				Code: influxdb.EInvalid,
				Err: &GroupCursorError{
					typ:    "float",
					cursor: cur,
				},
			}
			return false
		} else {
			t.readTags(t.gc.Tags())
			t.cur = typedCur
			return true
		}
	}
	return false
}

func (t *floatGroupTable) Statistics() cursors.CursorStats {
	if t.cur == nil {
		return cursors.CursorStats{}
	}
	cs := t.cur.Stats()
	return cursors.CursorStats{
		ScannedValues: cs.ScannedValues,
		ScannedBytes:  cs.ScannedBytes,
	}
}

//
// *********** Integer ***********
//

type integerTable struct {
	table
	mu    sync.Mutex
	cur   cursors.IntegerArrayCursor
	alloc *memory.Allocator
}

func newIntegerTable(
	done chan struct{},
	cur cursors.IntegerArrayCursor,
	bounds execute.Bounds,
	key flux.GroupKey,
	cols []flux.ColMeta,
	tags models.Tags,
	defs [][]byte,
	cache *tagsCache,
	alloc *memory.Allocator,
) *integerTable {
	t := &integerTable{
		table: newTable(done, bounds, key, cols, defs, cache, alloc),
		cur:   cur,
	}
	t.readTags(tags)
	t.advance()

	return t
}

func (t *integerTable) Close() {
	t.mu.Lock()
	if t.cur != nil {
		t.cur.Close()
		t.cur = nil
	}
	t.mu.Unlock()
}

func (t *integerTable) Statistics() cursors.CursorStats {
	t.mu.Lock()
	defer t.mu.Unlock()
	cur := t.cur
	if cur == nil {
		return cursors.CursorStats{}
	}
	cs := cur.Stats()
	return cursors.CursorStats{
		ScannedValues: cs.ScannedValues,
		ScannedBytes:  cs.ScannedBytes,
	}
}

func (t *integerTable) Do(f func(flux.ColReader) error) error {
	return t.do(f, t.advance)
}

func (t *integerTable) advance() bool {
	a := t.cur.Next()
	l := a.Len()
	if l == 0 {
		return false
	}

	// Retrieve the buffer for the data to avoid allocating
	// additional slices. If the buffer is still being used
	// because the references were retained, then we will
	// allocate a new buffer.
	cr := t.allocateBuffer(l)
	cr.cols[timeColIdx] = arrow.NewInt(a.Timestamps, t.alloc)
	cr.cols[valueColIdx] = t.toArrowBuffer(a.Values)
	t.appendTags(cr)
	t.appendBounds(cr)
	return true
}

// window table
type integerWindowTable struct {
	integerTable
	windowEvery int64
	arr         *cursors.IntegerArray
	idxInArr    int
}

func newIntegerWindowTable(
	done chan struct{},
	cur cursors.IntegerArrayCursor,
	bounds execute.Bounds,
	every int64,
	key flux.GroupKey,
	cols []flux.ColMeta,
	tags models.Tags,
	defs [][]byte,
	cache *tagsCache,
	alloc *memory.Allocator,
) *integerWindowTable {
	t := &integerWindowTable{
		integerTable: integerTable{
			table: newTable(done, bounds, key, cols, defs, cache, alloc),
			cur:   cur,
		},
		windowEvery: every,
	}
	t.readTags(tags)
	t.advance()

	return t
}

func (t *integerWindowTable) advance() bool {
	if t.arr == nil {
		t.arr = t.cur.Next()
		if t.arr.Len() == 0 {
			t.arr = nil
			return false
		}
		t.idxInArr = 0
	}

	// Retrieve the buffer for the data to avoid allocating
	// additional slices. If the buffer is still being used
	// because the references were retained, then we will
	// allocate a new buffer.
	columnReader := t.allocateBuffer(1)
	// regain the window start time from the window end time
	rangeStart := int64(t.bounds.Start)
	rangeEnd := int64(t.bounds.Stop)
	stop := t.arr.Timestamps[t.idxInArr]
	start := stop - t.windowEvery
	if start < rangeStart {
		start = rangeStart
	}
	if stop > rangeEnd {
		stop = rangeEnd
	}
	columnReader.cols[startColIdx] = arrow.NewInt([]int64{start}, t.alloc)
	columnReader.cols[stopColIdx] = arrow.NewInt([]int64{stop}, t.alloc)
	columnReader.cols[windowedValueColIdx] = t.toArrowBuffer(t.arr.Values[t.idxInArr : t.idxInArr+1])
	t.appendTags(columnReader)
	t.idxInArr++
	if t.idxInArr == t.arr.Len() {
		t.arr = nil
	}
	return true
}

type integerCompleteWindowTable struct {
	integerTable
	windowEvery int64
	ts          int64

	// Buffered state from the underlying cursor.
	timestamps []int64
	values     []int64
	i          int
	done       bool
}

func newIntegerCompleteWindowTable(
	done chan struct{},
	cur cursors.IntegerArrayCursor,
	bounds execute.Bounds,
	every int64,
	key flux.GroupKey,
	cols []flux.ColMeta,
	tags models.Tags,
	defs [][]byte,
	cache *tagsCache,
	alloc *memory.Allocator,
) *integerCompleteWindowTable {
	start := int64(bounds.Start)
	t := &integerCompleteWindowTable{
		integerTable: integerTable{
			table: newTable(done, bounds, key, cols, defs, cache, alloc),
			cur:   cur,
		},
		windowEvery: every,
		ts:          start + (every - start%every),
	}
	t.readTags(tags)
	t.advance()

	return t
}

// createWindows will create the next set of windows for each interval.
// The ts parameter is the first interval's stop time.
func (t *integerCompleteWindowTable) createWindows(ts int64) (next int64, start, stop *array.Int64) {
	n := int((int64(t.bounds.Stop) - ts) / t.windowEvery)
	if n > maxWindowBufferSize {
		n = maxWindowBufferSize
	}

	stopB := arrow.NewIntBuilder(t.alloc)
	stopB.Resize(n)
	for i, ts := 0, ts; i < n; i, ts = i+1, ts+t.windowEvery {
		if i == n-1 && ts > int64(t.bounds.Stop) {
			stopB.Append(int64(t.bounds.Stop))
			continue
		}
		stopB.Append(ts)
		next = ts
	}
	stop = stopB.NewInt64Array()

	startB := arrow.NewIntBuilder(t.alloc)
	startB.Resize(n)
	for i, ts := 0, ts-t.windowEvery; i < n; i, ts = i+1, ts+t.windowEvery {
		if i == 0 && ts < int64(t.bounds.Start) {
			startB.Append(int64(t.bounds.Start))
			continue
		}
		startB.Append(ts)
	}
	start = startB.NewInt64Array()
	return next, start, stop
}

func (t *integerCompleteWindowTable) nextAt(ts int64) (v int64, ok bool) {
	if t.i >= len(t.timestamps) && !t.nextBuffer() {
		return
	} else if t.timestamps[t.i] != ts {
		return
	}
	v, ok = t.values[t.i], true
	t.i++
	return v, ok
}

func (t *integerCompleteWindowTable) nextBuffer() bool {
	if t.done {
		return false
	}

	a := t.cur.Next()
	if a.Len() == 0 {
		t.done = true
		return false
	}
	t.timestamps = a.Timestamps
	t.values = a.Values
	t.i = 0
	return true
}

func (t *integerCompleteWindowTable) appendValues(intervals []int64, appendValue func(v int64), appendNull func()) {
	for i := 0; i < len(intervals); i++ {
		if v, ok := t.nextAt(intervals[i]); ok {
			appendValue(v)
			continue
		}
		appendNull()
	}
}

func (t *integerCompleteWindowTable) advance() bool {
	if t.ts-t.windowEvery >= int64(t.bounds.Stop) {
		return false
	}

	var start, stop *array.Int64
	t.ts, start, stop = t.createWindows(t.ts)

	for {
		if len(t.timestamps) == 0 && !t.done {
			a := t.cur.Next()
			if a.Len() == 0 {
				t.done = true
				break
			}
		}
	}
	values := t.mergeValues(stop.Int64Values())

	// Retrieve the buffer for the data to avoid allocating
	// additional slices. If the buffer is still being used
	// because the references were retained, then we will
	// allocate a new buffer.
	cr := t.allocateBuffer(stop.Len())
	cr.cols[startColIdx] = start
	cr.cols[stopColIdx] = stop
	cr.cols[windowedValueColIdx] = values
	t.appendTags(cr)
	return true
}

// group table

type integerGroupTable struct {
	table
	mu  sync.Mutex
	gc  storage.GroupCursor
	cur cursors.IntegerArrayCursor
}

func newIntegerGroupTable(
	done chan struct{},
	gc storage.GroupCursor,
	cur cursors.IntegerArrayCursor,
	bounds execute.Bounds,
	key flux.GroupKey,
	cols []flux.ColMeta,
	tags models.Tags,
	defs [][]byte,
	cache *tagsCache,
	alloc *memory.Allocator,
) *integerGroupTable {
	t := &integerGroupTable{
		table: newTable(done, bounds, key, cols, defs, cache, alloc),
		gc:    gc,
		cur:   cur,
	}
	t.readTags(tags)
	t.advance()

	return t
}

func (t *integerGroupTable) Close() {
	t.mu.Lock()
	if t.cur != nil {
		t.cur.Close()
		t.cur = nil
	}
	if t.gc != nil {
		t.gc.Close()
		t.gc = nil
	}
	t.mu.Unlock()
}

func (t *integerGroupTable) Do(f func(flux.ColReader) error) error {
	return t.do(f, t.advance)
}

func (t *integerGroupTable) advance() bool {
RETRY:
	a := t.cur.Next()
	l := a.Len()
	if l == 0 {
		if t.advanceCursor() {
			goto RETRY
		}

		return false
	}

	// Retrieve the buffer for the data to avoid allocating
	// additional slices. If the buffer is still being used
	// because the references were retained, then we will
	// allocate a new buffer.
	cr := t.allocateBuffer(l)
	cr.cols[timeColIdx] = arrow.NewInt(a.Timestamps, t.alloc)
	cr.cols[valueColIdx] = t.toArrowBuffer(a.Values)
	t.appendTags(cr)
	t.appendBounds(cr)
	return true
}

func (t *integerGroupTable) advanceCursor() bool {
	t.cur.Close()
	t.cur = nil
	for t.gc.Next() {
		cur := t.gc.Cursor()
		if cur == nil {
			continue
		}

		if typedCur, ok := cur.(cursors.IntegerArrayCursor); !ok {
			// TODO(sgc): error or skip?
			cur.Close()
			t.err = &influxdb.Error{
				Code: influxdb.EInvalid,
				Err: &GroupCursorError{
					typ:    "integer",
					cursor: cur,
				},
			}
			return false
		} else {
			t.readTags(t.gc.Tags())
			t.cur = typedCur
			return true
		}
	}
	return false
}

func (t *integerGroupTable) Statistics() cursors.CursorStats {
	if t.cur == nil {
		return cursors.CursorStats{}
	}
	cs := t.cur.Stats()
	return cursors.CursorStats{
		ScannedValues: cs.ScannedValues,
		ScannedBytes:  cs.ScannedBytes,
	}
}

//
// *********** Unsigned ***********
//

type unsignedTable struct {
	table
	mu    sync.Mutex
	cur   cursors.UnsignedArrayCursor
	alloc *memory.Allocator
}

func newUnsignedTable(
	done chan struct{},
	cur cursors.UnsignedArrayCursor,
	bounds execute.Bounds,
	key flux.GroupKey,
	cols []flux.ColMeta,
	tags models.Tags,
	defs [][]byte,
	cache *tagsCache,
	alloc *memory.Allocator,
) *unsignedTable {
	t := &unsignedTable{
		table: newTable(done, bounds, key, cols, defs, cache, alloc),
		cur:   cur,
	}
	t.readTags(tags)
	t.advance()

	return t
}

func (t *unsignedTable) Close() {
	t.mu.Lock()
	if t.cur != nil {
		t.cur.Close()
		t.cur = nil
	}
	t.mu.Unlock()
}

func (t *unsignedTable) Statistics() cursors.CursorStats {
	t.mu.Lock()
	defer t.mu.Unlock()
	cur := t.cur
	if cur == nil {
		return cursors.CursorStats{}
	}
	cs := cur.Stats()
	return cursors.CursorStats{
		ScannedValues: cs.ScannedValues,
		ScannedBytes:  cs.ScannedBytes,
	}
}

func (t *unsignedTable) Do(f func(flux.ColReader) error) error {
	return t.do(f, t.advance)
}

func (t *unsignedTable) advance() bool {
	a := t.cur.Next()
	l := a.Len()
	if l == 0 {
		return false
	}

	// Retrieve the buffer for the data to avoid allocating
	// additional slices. If the buffer is still being used
	// because the references were retained, then we will
	// allocate a new buffer.
	cr := t.allocateBuffer(l)
	cr.cols[timeColIdx] = arrow.NewInt(a.Timestamps, t.alloc)
	cr.cols[valueColIdx] = t.toArrowBuffer(a.Values)
	t.appendTags(cr)
	t.appendBounds(cr)
	return true
}

// window table
type unsignedWindowTable struct {
	unsignedTable
	windowEvery int64
	arr         *cursors.UnsignedArray
	idxInArr    int
}

func newUnsignedWindowTable(
	done chan struct{},
	cur cursors.UnsignedArrayCursor,
	bounds execute.Bounds,
	every int64,
	key flux.GroupKey,
	cols []flux.ColMeta,
	tags models.Tags,
	defs [][]byte,
	cache *tagsCache,
	alloc *memory.Allocator,
) *unsignedWindowTable {
	t := &unsignedWindowTable{
		unsignedTable: unsignedTable{
			table: newTable(done, bounds, key, cols, defs, cache, alloc),
			cur:   cur,
		},
		windowEvery: every,
	}
	t.readTags(tags)
	t.advance()

	return t
}

func (t *unsignedWindowTable) advance() bool {
	if t.arr == nil {
		t.arr = t.cur.Next()
		if t.arr.Len() == 0 {
			t.arr = nil
			return false
		}
		t.idxInArr = 0
	}

	// Retrieve the buffer for the data to avoid allocating
	// additional slices. If the buffer is still being used
	// because the references were retained, then we will
	// allocate a new buffer.
	columnReader := t.allocateBuffer(1)
	// regain the window start time from the window end time
	rangeStart := int64(t.bounds.Start)
	rangeEnd := int64(t.bounds.Stop)
	stop := t.arr.Timestamps[t.idxInArr]
	start := stop - t.windowEvery
	if start < rangeStart {
		start = rangeStart
	}
	if stop > rangeEnd {
		stop = rangeEnd
	}
	columnReader.cols[startColIdx] = arrow.NewInt([]int64{start}, t.alloc)
	columnReader.cols[stopColIdx] = arrow.NewInt([]int64{stop}, t.alloc)
	columnReader.cols[windowedValueColIdx] = t.toArrowBuffer(t.arr.Values[t.idxInArr : t.idxInArr+1])
	t.appendTags(columnReader)
	t.idxInArr++
	if t.idxInArr == t.arr.Len() {
		t.arr = nil
	}
	return true
}

type unsignedCompleteWindowTable struct {
	unsignedTable
	windowEvery int64
	ts          int64

	// Buffered state from the underlying cursor.
	timestamps []int64
	values     []uint64
	i          int
	done       bool
}

func newUnsignedCompleteWindowTable(
	done chan struct{},
	cur cursors.UnsignedArrayCursor,
	bounds execute.Bounds,
	every int64,
	key flux.GroupKey,
	cols []flux.ColMeta,
	tags models.Tags,
	defs [][]byte,
	cache *tagsCache,
	alloc *memory.Allocator,
) *unsignedCompleteWindowTable {
	start := int64(bounds.Start)
	t := &unsignedCompleteWindowTable{
		unsignedTable: unsignedTable{
			table: newTable(done, bounds, key, cols, defs, cache, alloc),
			cur:   cur,
		},
		windowEvery: every,
		ts:          start + (every - start%every),
	}
	t.readTags(tags)
	t.advance()

	return t
}

// createWindows will create the next set of windows for each interval.
// The ts parameter is the first interval's stop time.
func (t *unsignedCompleteWindowTable) createWindows(ts int64) (next int64, start, stop *array.Int64) {
	n := int((int64(t.bounds.Stop) - ts) / t.windowEvery)
	if n > maxWindowBufferSize {
		n = maxWindowBufferSize
	}

	stopB := arrow.NewIntBuilder(t.alloc)
	stopB.Resize(n)
	for i, ts := 0, ts; i < n; i, ts = i+1, ts+t.windowEvery {
		if i == n-1 && ts > int64(t.bounds.Stop) {
			stopB.Append(int64(t.bounds.Stop))
			continue
		}
		stopB.Append(ts)
		next = ts
	}
	stop = stopB.NewInt64Array()

	startB := arrow.NewIntBuilder(t.alloc)
	startB.Resize(n)
	for i, ts := 0, ts-t.windowEvery; i < n; i, ts = i+1, ts+t.windowEvery {
		if i == 0 && ts < int64(t.bounds.Start) {
			startB.Append(int64(t.bounds.Start))
			continue
		}
		startB.Append(ts)
	}
	start = startB.NewInt64Array()
	return next, start, stop
}

func (t *unsignedCompleteWindowTable) nextAt(ts int64) (v uint64, ok bool) {
	if t.i >= len(t.timestamps) && !t.nextBuffer() {
		return
	} else if t.timestamps[t.i] != ts {
		return
	}
	v, ok = t.values[t.i], true
	t.i++
	return v, ok
}

func (t *unsignedCompleteWindowTable) nextBuffer() bool {
	if t.done {
		return false
	}

	a := t.cur.Next()
	if a.Len() == 0 {
		t.done = true
		return false
	}
	t.timestamps = a.Timestamps
	t.values = a.Values
	t.i = 0
	return true
}

func (t *unsignedCompleteWindowTable) appendValues(intervals []int64, appendValue func(v uint64), appendNull func()) {
	for i := 0; i < len(intervals); i++ {
		if v, ok := t.nextAt(intervals[i]); ok {
			appendValue(v)
			continue
		}
		appendNull()
	}
}

func (t *unsignedCompleteWindowTable) advance() bool {
	if t.ts-t.windowEvery >= int64(t.bounds.Stop) {
		return false
	}

	var start, stop *array.Int64
	t.ts, start, stop = t.createWindows(t.ts)

	for {
		if len(t.timestamps) == 0 && !t.done {
			a := t.cur.Next()
			if a.Len() == 0 {
				t.done = true
				break
			}
		}
	}
	values := t.mergeValues(stop.Int64Values())

	// Retrieve the buffer for the data to avoid allocating
	// additional slices. If the buffer is still being used
	// because the references were retained, then we will
	// allocate a new buffer.
	cr := t.allocateBuffer(stop.Len())
	cr.cols[startColIdx] = start
	cr.cols[stopColIdx] = stop
	cr.cols[windowedValueColIdx] = values
	t.appendTags(cr)
	return true
}

// group table

type unsignedGroupTable struct {
	table
	mu  sync.Mutex
	gc  storage.GroupCursor
	cur cursors.UnsignedArrayCursor
}

func newUnsignedGroupTable(
	done chan struct{},
	gc storage.GroupCursor,
	cur cursors.UnsignedArrayCursor,
	bounds execute.Bounds,
	key flux.GroupKey,
	cols []flux.ColMeta,
	tags models.Tags,
	defs [][]byte,
	cache *tagsCache,
	alloc *memory.Allocator,
) *unsignedGroupTable {
	t := &unsignedGroupTable{
		table: newTable(done, bounds, key, cols, defs, cache, alloc),
		gc:    gc,
		cur:   cur,
	}
	t.readTags(tags)
	t.advance()

	return t
}

func (t *unsignedGroupTable) Close() {
	t.mu.Lock()
	if t.cur != nil {
		t.cur.Close()
		t.cur = nil
	}
	if t.gc != nil {
		t.gc.Close()
		t.gc = nil
	}
	t.mu.Unlock()
}

func (t *unsignedGroupTable) Do(f func(flux.ColReader) error) error {
	return t.do(f, t.advance)
}

func (t *unsignedGroupTable) advance() bool {
RETRY:
	a := t.cur.Next()
	l := a.Len()
	if l == 0 {
		if t.advanceCursor() {
			goto RETRY
		}

		return false
	}

	// Retrieve the buffer for the data to avoid allocating
	// additional slices. If the buffer is still being used
	// because the references were retained, then we will
	// allocate a new buffer.
	cr := t.allocateBuffer(l)
	cr.cols[timeColIdx] = arrow.NewInt(a.Timestamps, t.alloc)
	cr.cols[valueColIdx] = t.toArrowBuffer(a.Values)
	t.appendTags(cr)
	t.appendBounds(cr)
	return true
}

func (t *unsignedGroupTable) advanceCursor() bool {
	t.cur.Close()
	t.cur = nil
	for t.gc.Next() {
		cur := t.gc.Cursor()
		if cur == nil {
			continue
		}

		if typedCur, ok := cur.(cursors.UnsignedArrayCursor); !ok {
			// TODO(sgc): error or skip?
			cur.Close()
			t.err = &influxdb.Error{
				Code: influxdb.EInvalid,
				Err: &GroupCursorError{
					typ:    "unsigned",
					cursor: cur,
				},
			}
			return false
		} else {
			t.readTags(t.gc.Tags())
			t.cur = typedCur
			return true
		}
	}
	return false
}

func (t *unsignedGroupTable) Statistics() cursors.CursorStats {
	if t.cur == nil {
		return cursors.CursorStats{}
	}
	cs := t.cur.Stats()
	return cursors.CursorStats{
		ScannedValues: cs.ScannedValues,
		ScannedBytes:  cs.ScannedBytes,
	}
}

//
// *********** String ***********
//

type stringTable struct {
	table
	mu    sync.Mutex
	cur   cursors.StringArrayCursor
	alloc *memory.Allocator
}

func newStringTable(
	done chan struct{},
	cur cursors.StringArrayCursor,
	bounds execute.Bounds,
	key flux.GroupKey,
	cols []flux.ColMeta,
	tags models.Tags,
	defs [][]byte,
	cache *tagsCache,
	alloc *memory.Allocator,
) *stringTable {
	t := &stringTable{
		table: newTable(done, bounds, key, cols, defs, cache, alloc),
		cur:   cur,
	}
	t.readTags(tags)
	t.advance()

	return t
}

func (t *stringTable) Close() {
	t.mu.Lock()
	if t.cur != nil {
		t.cur.Close()
		t.cur = nil
	}
	t.mu.Unlock()
}

func (t *stringTable) Statistics() cursors.CursorStats {
	t.mu.Lock()
	defer t.mu.Unlock()
	cur := t.cur
	if cur == nil {
		return cursors.CursorStats{}
	}
	cs := cur.Stats()
	return cursors.CursorStats{
		ScannedValues: cs.ScannedValues,
		ScannedBytes:  cs.ScannedBytes,
	}
}

func (t *stringTable) Do(f func(flux.ColReader) error) error {
	return t.do(f, t.advance)
}

func (t *stringTable) advance() bool {
	a := t.cur.Next()
	l := a.Len()
	if l == 0 {
		return false
	}

	// Retrieve the buffer for the data to avoid allocating
	// additional slices. If the buffer is still being used
	// because the references were retained, then we will
	// allocate a new buffer.
	cr := t.allocateBuffer(l)
	cr.cols[timeColIdx] = arrow.NewInt(a.Timestamps, t.alloc)
	cr.cols[valueColIdx] = t.toArrowBuffer(a.Values)
	t.appendTags(cr)
	t.appendBounds(cr)
	return true
}

// window table
type stringWindowTable struct {
	stringTable
	windowEvery int64
	arr         *cursors.StringArray
	idxInArr    int
}

func newStringWindowTable(
	done chan struct{},
	cur cursors.StringArrayCursor,
	bounds execute.Bounds,
	every int64,
	key flux.GroupKey,
	cols []flux.ColMeta,
	tags models.Tags,
	defs [][]byte,
	cache *tagsCache,
	alloc *memory.Allocator,
) *stringWindowTable {
	t := &stringWindowTable{
		stringTable: stringTable{
			table: newTable(done, bounds, key, cols, defs, cache, alloc),
			cur:   cur,
		},
		windowEvery: every,
	}
	t.readTags(tags)
	t.advance()

	return t
}

func (t *stringWindowTable) advance() bool {
	if t.arr == nil {
		t.arr = t.cur.Next()
		if t.arr.Len() == 0 {
			t.arr = nil
			return false
		}
		t.idxInArr = 0
	}

	// Retrieve the buffer for the data to avoid allocating
	// additional slices. If the buffer is still being used
	// because the references were retained, then we will
	// allocate a new buffer.
	columnReader := t.allocateBuffer(1)
	// regain the window start time from the window end time
	rangeStart := int64(t.bounds.Start)
	rangeEnd := int64(t.bounds.Stop)
	stop := t.arr.Timestamps[t.idxInArr]
	start := stop - t.windowEvery
	if start < rangeStart {
		start = rangeStart
	}
	if stop > rangeEnd {
		stop = rangeEnd
	}
	columnReader.cols[startColIdx] = arrow.NewInt([]int64{start}, t.alloc)
	columnReader.cols[stopColIdx] = arrow.NewInt([]int64{stop}, t.alloc)
	columnReader.cols[windowedValueColIdx] = t.toArrowBuffer(t.arr.Values[t.idxInArr : t.idxInArr+1])
	t.appendTags(columnReader)
	t.idxInArr++
	if t.idxInArr == t.arr.Len() {
		t.arr = nil
	}
	return true
}

type stringCompleteWindowTable struct {
	stringTable
	windowEvery int64
	ts          int64

	// Buffered state from the underlying cursor.
	timestamps []int64
	values     []string
	i          int
	done       bool
}

func newStringCompleteWindowTable(
	done chan struct{},
	cur cursors.StringArrayCursor,
	bounds execute.Bounds,
	every int64,
	key flux.GroupKey,
	cols []flux.ColMeta,
	tags models.Tags,
	defs [][]byte,
	cache *tagsCache,
	alloc *memory.Allocator,
) *stringCompleteWindowTable {
	start := int64(bounds.Start)
	t := &stringCompleteWindowTable{
		stringTable: stringTable{
			table: newTable(done, bounds, key, cols, defs, cache, alloc),
			cur:   cur,
		},
		windowEvery: every,
		ts:          start + (every - start%every),
	}
	t.readTags(tags)
	t.advance()

	return t
}

// createWindows will create the next set of windows for each interval.
// The ts parameter is the first interval's stop time.
func (t *stringCompleteWindowTable) createWindows(ts int64) (next int64, start, stop *array.Int64) {
	n := int((int64(t.bounds.Stop) - ts) / t.windowEvery)
	if n > maxWindowBufferSize {
		n = maxWindowBufferSize
	}

	stopB := arrow.NewIntBuilder(t.alloc)
	stopB.Resize(n)
	for i, ts := 0, ts; i < n; i, ts = i+1, ts+t.windowEvery {
		if i == n-1 && ts > int64(t.bounds.Stop) {
			stopB.Append(int64(t.bounds.Stop))
			continue
		}
		stopB.Append(ts)
		next = ts
	}
	stop = stopB.NewInt64Array()

	startB := arrow.NewIntBuilder(t.alloc)
	startB.Resize(n)
	for i, ts := 0, ts-t.windowEvery; i < n; i, ts = i+1, ts+t.windowEvery {
		if i == 0 && ts < int64(t.bounds.Start) {
			startB.Append(int64(t.bounds.Start))
			continue
		}
		startB.Append(ts)
	}
	start = startB.NewInt64Array()
	return next, start, stop
}

func (t *stringCompleteWindowTable) nextAt(ts int64) (v string, ok bool) {
	if t.i >= len(t.timestamps) && !t.nextBuffer() {
		return
	} else if t.timestamps[t.i] != ts {
		return
	}
	v, ok = t.values[t.i], true
	t.i++
	return v, ok
}

func (t *stringCompleteWindowTable) nextBuffer() bool {
	if t.done {
		return false
	}

	a := t.cur.Next()
	if a.Len() == 0 {
		t.done = true
		return false
	}
	t.timestamps = a.Timestamps
	t.values = a.Values
	t.i = 0
	return true
}

func (t *stringCompleteWindowTable) appendValues(intervals []int64, appendValue func(v string), appendNull func()) {
	for i := 0; i < len(intervals); i++ {
		if v, ok := t.nextAt(intervals[i]); ok {
			appendValue(v)
			continue
		}
		appendNull()
	}
}

func (t *stringCompleteWindowTable) advance() bool {
	if t.ts-t.windowEvery >= int64(t.bounds.Stop) {
		return false
	}

	var start, stop *array.Int64
	t.ts, start, stop = t.createWindows(t.ts)

	for {
		if len(t.timestamps) == 0 && !t.done {
			a := t.cur.Next()
			if a.Len() == 0 {
				t.done = true
				break
			}
		}
	}
	values := t.mergeValues(stop.Int64Values())

	// Retrieve the buffer for the data to avoid allocating
	// additional slices. If the buffer is still being used
	// because the references were retained, then we will
	// allocate a new buffer.
	cr := t.allocateBuffer(stop.Len())
	cr.cols[startColIdx] = start
	cr.cols[stopColIdx] = stop
	cr.cols[windowedValueColIdx] = values
	t.appendTags(cr)
	return true
}

// group table

type stringGroupTable struct {
	table
	mu  sync.Mutex
	gc  storage.GroupCursor
	cur cursors.StringArrayCursor
}

func newStringGroupTable(
	done chan struct{},
	gc storage.GroupCursor,
	cur cursors.StringArrayCursor,
	bounds execute.Bounds,
	key flux.GroupKey,
	cols []flux.ColMeta,
	tags models.Tags,
	defs [][]byte,
	cache *tagsCache,
	alloc *memory.Allocator,
) *stringGroupTable {
	t := &stringGroupTable{
		table: newTable(done, bounds, key, cols, defs, cache, alloc),
		gc:    gc,
		cur:   cur,
	}
	t.readTags(tags)
	t.advance()

	return t
}

func (t *stringGroupTable) Close() {
	t.mu.Lock()
	if t.cur != nil {
		t.cur.Close()
		t.cur = nil
	}
	if t.gc != nil {
		t.gc.Close()
		t.gc = nil
	}
	t.mu.Unlock()
}

func (t *stringGroupTable) Do(f func(flux.ColReader) error) error {
	return t.do(f, t.advance)
}

func (t *stringGroupTable) advance() bool {
RETRY:
	a := t.cur.Next()
	l := a.Len()
	if l == 0 {
		if t.advanceCursor() {
			goto RETRY
		}

		return false
	}

	// Retrieve the buffer for the data to avoid allocating
	// additional slices. If the buffer is still being used
	// because the references were retained, then we will
	// allocate a new buffer.
	cr := t.allocateBuffer(l)
	cr.cols[timeColIdx] = arrow.NewInt(a.Timestamps, t.alloc)
	cr.cols[valueColIdx] = t.toArrowBuffer(a.Values)
	t.appendTags(cr)
	t.appendBounds(cr)
	return true
}

func (t *stringGroupTable) advanceCursor() bool {
	t.cur.Close()
	t.cur = nil
	for t.gc.Next() {
		cur := t.gc.Cursor()
		if cur == nil {
			continue
		}

		if typedCur, ok := cur.(cursors.StringArrayCursor); !ok {
			// TODO(sgc): error or skip?
			cur.Close()
			t.err = &influxdb.Error{
				Code: influxdb.EInvalid,
				Err: &GroupCursorError{
					typ:    "string",
					cursor: cur,
				},
			}
			return false
		} else {
			t.readTags(t.gc.Tags())
			t.cur = typedCur
			return true
		}
	}
	return false
}

func (t *stringGroupTable) Statistics() cursors.CursorStats {
	if t.cur == nil {
		return cursors.CursorStats{}
	}
	cs := t.cur.Stats()
	return cursors.CursorStats{
		ScannedValues: cs.ScannedValues,
		ScannedBytes:  cs.ScannedBytes,
	}
}

//
// *********** Boolean ***********
//

type booleanTable struct {
	table
	mu    sync.Mutex
	cur   cursors.BooleanArrayCursor
	alloc *memory.Allocator
}

func newBooleanTable(
	done chan struct{},
	cur cursors.BooleanArrayCursor,
	bounds execute.Bounds,
	key flux.GroupKey,
	cols []flux.ColMeta,
	tags models.Tags,
	defs [][]byte,
	cache *tagsCache,
	alloc *memory.Allocator,
) *booleanTable {
	t := &booleanTable{
		table: newTable(done, bounds, key, cols, defs, cache, alloc),
		cur:   cur,
	}
	t.readTags(tags)
	t.advance()

	return t
}

func (t *booleanTable) Close() {
	t.mu.Lock()
	if t.cur != nil {
		t.cur.Close()
		t.cur = nil
	}
	t.mu.Unlock()
}

func (t *booleanTable) Statistics() cursors.CursorStats {
	t.mu.Lock()
	defer t.mu.Unlock()
	cur := t.cur
	if cur == nil {
		return cursors.CursorStats{}
	}
	cs := cur.Stats()
	return cursors.CursorStats{
		ScannedValues: cs.ScannedValues,
		ScannedBytes:  cs.ScannedBytes,
	}
}

func (t *booleanTable) Do(f func(flux.ColReader) error) error {
	return t.do(f, t.advance)
}

func (t *booleanTable) advance() bool {
	a := t.cur.Next()
	l := a.Len()
	if l == 0 {
		return false
	}

	// Retrieve the buffer for the data to avoid allocating
	// additional slices. If the buffer is still being used
	// because the references were retained, then we will
	// allocate a new buffer.
	cr := t.allocateBuffer(l)
	cr.cols[timeColIdx] = arrow.NewInt(a.Timestamps, t.alloc)
	cr.cols[valueColIdx] = t.toArrowBuffer(a.Values)
	t.appendTags(cr)
	t.appendBounds(cr)
	return true
}

// window table
type booleanWindowTable struct {
	booleanTable
	windowEvery int64
	arr         *cursors.BooleanArray
	idxInArr    int
}

func newBooleanWindowTable(
	done chan struct{},
	cur cursors.BooleanArrayCursor,
	bounds execute.Bounds,
	every int64,
	key flux.GroupKey,
	cols []flux.ColMeta,
	tags models.Tags,
	defs [][]byte,
	cache *tagsCache,
	alloc *memory.Allocator,
) *booleanWindowTable {
	t := &booleanWindowTable{
		booleanTable: booleanTable{
			table: newTable(done, bounds, key, cols, defs, cache, alloc),
			cur:   cur,
		},
		windowEvery: every,
	}
	t.readTags(tags)
	t.advance()

	return t
}

func (t *booleanWindowTable) advance() bool {
	if t.arr == nil {
		t.arr = t.cur.Next()
		if t.arr.Len() == 0 {
			t.arr = nil
			return false
		}
		t.idxInArr = 0
	}

	// Retrieve the buffer for the data to avoid allocating
	// additional slices. If the buffer is still being used
	// because the references were retained, then we will
	// allocate a new buffer.
	columnReader := t.allocateBuffer(1)
	// regain the window start time from the window end time
	rangeStart := int64(t.bounds.Start)
	rangeEnd := int64(t.bounds.Stop)
	stop := t.arr.Timestamps[t.idxInArr]
	start := stop - t.windowEvery
	if start < rangeStart {
		start = rangeStart
	}
	if stop > rangeEnd {
		stop = rangeEnd
	}
	columnReader.cols[startColIdx] = arrow.NewInt([]int64{start}, t.alloc)
	columnReader.cols[stopColIdx] = arrow.NewInt([]int64{stop}, t.alloc)
	columnReader.cols[windowedValueColIdx] = t.toArrowBuffer(t.arr.Values[t.idxInArr : t.idxInArr+1])
	t.appendTags(columnReader)
	t.idxInArr++
	if t.idxInArr == t.arr.Len() {
		t.arr = nil
	}
	return true
}

type booleanCompleteWindowTable struct {
	booleanTable
	windowEvery int64
	ts          int64

	// Buffered state from the underlying cursor.
	timestamps []int64
	values     []bool
	i          int
	done       bool
}

func newBooleanCompleteWindowTable(
	done chan struct{},
	cur cursors.BooleanArrayCursor,
	bounds execute.Bounds,
	every int64,
	key flux.GroupKey,
	cols []flux.ColMeta,
	tags models.Tags,
	defs [][]byte,
	cache *tagsCache,
	alloc *memory.Allocator,
) *booleanCompleteWindowTable {
	start := int64(bounds.Start)
	t := &booleanCompleteWindowTable{
		booleanTable: booleanTable{
			table: newTable(done, bounds, key, cols, defs, cache, alloc),
			cur:   cur,
		},
		windowEvery: every,
		ts:          start + (every - start%every),
	}
	t.readTags(tags)
	t.advance()

	return t
}

// createWindows will create the next set of windows for each interval.
// The ts parameter is the first interval's stop time.
func (t *booleanCompleteWindowTable) createWindows(ts int64) (next int64, start, stop *array.Int64) {
	n := int((int64(t.bounds.Stop) - ts) / t.windowEvery)
	if n > maxWindowBufferSize {
		n = maxWindowBufferSize
	}

	stopB := arrow.NewIntBuilder(t.alloc)
	stopB.Resize(n)
	for i, ts := 0, ts; i < n; i, ts = i+1, ts+t.windowEvery {
		if i == n-1 && ts > int64(t.bounds.Stop) {
			stopB.Append(int64(t.bounds.Stop))
			continue
		}
		stopB.Append(ts)
		next = ts
	}
	stop = stopB.NewInt64Array()

	startB := arrow.NewIntBuilder(t.alloc)
	startB.Resize(n)
	for i, ts := 0, ts-t.windowEvery; i < n; i, ts = i+1, ts+t.windowEvery {
		if i == 0 && ts < int64(t.bounds.Start) {
			startB.Append(int64(t.bounds.Start))
			continue
		}
		startB.Append(ts)
	}
	start = startB.NewInt64Array()
	return next, start, stop
}

func (t *booleanCompleteWindowTable) nextAt(ts int64) (v bool, ok bool) {
	if t.i >= len(t.timestamps) && !t.nextBuffer() {
		return
	} else if t.timestamps[t.i] != ts {
		return
	}
	v, ok = t.values[t.i], true
	t.i++
	return v, ok
}

func (t *booleanCompleteWindowTable) nextBuffer() bool {
	if t.done {
		return false
	}

	a := t.cur.Next()
	if a.Len() == 0 {
		t.done = true
		return false
	}
	t.timestamps = a.Timestamps
	t.values = a.Values
	t.i = 0
	return true
}

func (t *booleanCompleteWindowTable) appendValues(intervals []int64, appendValue func(v bool), appendNull func()) {
	for i := 0; i < len(intervals); i++ {
		if v, ok := t.nextAt(intervals[i]); ok {
			appendValue(v)
			continue
		}
		appendNull()
	}
}

func (t *booleanCompleteWindowTable) advance() bool {
	if t.ts-t.windowEvery >= int64(t.bounds.Stop) {
		return false
	}

	var start, stop *array.Int64
	t.ts, start, stop = t.createWindows(t.ts)

	for {
		if len(t.timestamps) == 0 && !t.done {
			a := t.cur.Next()
			if a.Len() == 0 {
				t.done = true
				break
			}
		}
	}
	values := t.mergeValues(stop.Int64Values())

	// Retrieve the buffer for the data to avoid allocating
	// additional slices. If the buffer is still being used
	// because the references were retained, then we will
	// allocate a new buffer.
	cr := t.allocateBuffer(stop.Len())
	cr.cols[startColIdx] = start
	cr.cols[stopColIdx] = stop
	cr.cols[windowedValueColIdx] = values
	t.appendTags(cr)
	return true
}

// group table

type booleanGroupTable struct {
	table
	mu  sync.Mutex
	gc  storage.GroupCursor
	cur cursors.BooleanArrayCursor
}

func newBooleanGroupTable(
	done chan struct{},
	gc storage.GroupCursor,
	cur cursors.BooleanArrayCursor,
	bounds execute.Bounds,
	key flux.GroupKey,
	cols []flux.ColMeta,
	tags models.Tags,
	defs [][]byte,
	cache *tagsCache,
	alloc *memory.Allocator,
) *booleanGroupTable {
	t := &booleanGroupTable{
		table: newTable(done, bounds, key, cols, defs, cache, alloc),
		gc:    gc,
		cur:   cur,
	}
	t.readTags(tags)
	t.advance()

	return t
}

func (t *booleanGroupTable) Close() {
	t.mu.Lock()
	if t.cur != nil {
		t.cur.Close()
		t.cur = nil
	}
	if t.gc != nil {
		t.gc.Close()
		t.gc = nil
	}
	t.mu.Unlock()
}

func (t *booleanGroupTable) Do(f func(flux.ColReader) error) error {
	return t.do(f, t.advance)
}

func (t *booleanGroupTable) advance() bool {
RETRY:
	a := t.cur.Next()
	l := a.Len()
	if l == 0 {
		if t.advanceCursor() {
			goto RETRY
		}

		return false
	}

	// Retrieve the buffer for the data to avoid allocating
	// additional slices. If the buffer is still being used
	// because the references were retained, then we will
	// allocate a new buffer.
	cr := t.allocateBuffer(l)
	cr.cols[timeColIdx] = arrow.NewInt(a.Timestamps, t.alloc)
	cr.cols[valueColIdx] = t.toArrowBuffer(a.Values)
	t.appendTags(cr)
	t.appendBounds(cr)
	return true
}

func (t *booleanGroupTable) advanceCursor() bool {
	t.cur.Close()
	t.cur = nil
	for t.gc.Next() {
		cur := t.gc.Cursor()
		if cur == nil {
			continue
		}

		if typedCur, ok := cur.(cursors.BooleanArrayCursor); !ok {
			// TODO(sgc): error or skip?
			cur.Close()
			t.err = &influxdb.Error{
				Code: influxdb.EInvalid,
				Err: &GroupCursorError{
					typ:    "boolean",
					cursor: cur,
				},
			}
			return false
		} else {
			t.readTags(t.gc.Tags())
			t.cur = typedCur
			return true
		}
	}
	return false
}

func (t *booleanGroupTable) Statistics() cursors.CursorStats {
	if t.cur == nil {
		return cursors.CursorStats{}
	}
	cs := t.cur.Stats()
	return cursors.CursorStats{
		ScannedValues: cs.ScannedValues,
		ScannedBytes:  cs.ScannedBytes,
	}
}
